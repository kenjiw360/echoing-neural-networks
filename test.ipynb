{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENNModel(nn.Module):\n",
    "\tdef __init__(self, in_channels, num_classes=10, echoing_depth=5, echoing_limit=5):\n",
    "\t\tsuper(ENNModel, self).__init__()\n",
    "\t\tself.in_channels = in_channels\n",
    "\t\tself.num_classes = num_classes\n",
    "\t\tself.echoing_depth = echoing_depth\n",
    "\t\tself.echoing_limit = echoing_limit\n",
    "\n",
    "\t\tself.conv_layers = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(self.in_channels, 64, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tnn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tnn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tnn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tnn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\t\t)\n",
    "\n",
    "\t\t# fully connected linear layers\n",
    "\t\tself.linear1 = nn.Linear(in_features=512*7*7, out_features = 1024)\n",
    "\t\tself.linear_echoing_layers = nn.ModuleList([*[nn.Linear(in_features=1024, out_features=1024) for i in range(self.echoing_depth)], nn.Linear(in_features=1024, out_features=self.num_classes)])\n",
    "\t\t# self.linear1 = nn.Linear(in_features=512*7*7, out_features=1024)\n",
    "\t\t# self.linear2 = nn.Linear(in_features=1024, out_features=1024)\n",
    "\t\t# self.linear3 = nn.Linear(in_features=1024, out_features=1024)\n",
    "\t\t# self.linear4 = nn.Linear(in_features=1024, out_features=1024)\n",
    "\t\t# self.linear5 = nn.Linear(in_features=1024, out_features=self.num_classes)\n",
    "\tdef run_echo_chamber(self, input, index, echoing_complete):\n",
    "\t\toutput = nn.functional.dropout2d(nn.functional.relu(self.linear_echoing_layers[index](input)))\n",
    "\t\tif(index != self.echoing_depth - 1): branch_2 = self.run_echo_chamber(self, output, index + 1)\n",
    "\t\telif(torch.max(nn.Softmax()(output)) > 0.5 and not echoing_complete[0]):\n",
    "\t\t\techoing_complete[0] = True\n",
    "\t\t\treturn output\n",
    "\t\tif(index != 0 and not echoing_complete[0]): branch_1 = self.run_echo_chamber(self, output, index - 1)\n",
    "\t\treturn branch_1 or branch_2\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tconv_output = self.conv_layers(x)\n",
    "\t\tconv_output_flat = conv_output.view(conv_output.size(0), -1)\n",
    "\n",
    "\t\techoing_input = self.linear1(conv_output_flat)\n",
    "\n",
    "\t\techoing_complete = [False]\n",
    "\t\techoing_output = self.run_echo_chamber(self, echoing_input, 0, echoing_complete)\n",
    "\n",
    "\t\treturn echoing_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG11(nn.Module):\n",
    "\tdef __init__(self, in_channels, num_classes=10):\n",
    "\t\tsuper(VGG11, self).__init__()\n",
    "\t\tself.in_channels = in_channels\n",
    "\t\tself.num_classes = num_classes\n",
    "\t\tself.conv_layers = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(self.in_channels, 64, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tnn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tnn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tnn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\t\t\tnn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\t\t)\n",
    "\t\tself.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "\t\tself.linear_layers = nn.Sequential(\n",
    "\t\t\tnn.Linear(in_features=512*7*7, out_features=4096),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(0.5),\n",
    "\t\t\tnn.Linear(in_features=4096, out_features=4096),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Dropout(0.5),\n",
    "\t\t\tnn.Linear(in_features=4096, out_features=self.num_classes)\n",
    "\t\t)\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.conv_layers(x)\n",
    "\t\tprint(\"finished conv layers\")\n",
    "\t\t# flatten to prepare for the fully connected layers\n",
    "\t\tx = self.avgpool(x)\n",
    "\t\tprint(\"avgpooled conv output\")\n",
    "\t\tx = torch.flatten(x)\n",
    "\t\tprint(\"flattened conv output\", torch.Tensor.dim(x))\n",
    "\t\tx = self.linear_layers(x)\n",
    "\t\tprint(\"finished linear layers\")\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "\t[transforms.ToTensor(),\n",
    "\t transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "training_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "validationset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(validationset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "\t\t   'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = VGG11(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "\trunning_loss = 0.\n",
    "\tlast_loss = 0.\n",
    "\n",
    "\t# Here, we use enumerate(training_loader) instead of\n",
    "\t# iter(training_loader) so that we can track the batch\n",
    "\t# index and do some intra-epoch reporting\n",
    "\tfor i, data in enumerate(training_loader):\n",
    "\t\t# Every data instance is an input + label pair\n",
    "\t\tinputs, labels = data\n",
    "\t\toutputs = []\n",
    "\n",
    "\t\t# Zero your gradients for every batch!\n",
    "\t\toptimiser.zero_grad()\n",
    "\n",
    "\t\tfor j in range(batch_size):\n",
    "\t\t\t# Make predictions for this batch\n",
    "\t\t\toutputs.append(cnn(inputs[j]))\n",
    "\n",
    "\t\t\t# Compute the loss and its gradients\n",
    "\t\tloss = criterion(torch.stack(outputs), labels)\n",
    "\t\trunning_loss += loss\n",
    "\t\tloss.backward()\n",
    "\n",
    "\t\t# Adjust learning weights\n",
    "\t\toptimiser.step()\n",
    "\n",
    "\t\t# Gather data and report\n",
    "\t\tif i % 1000 == 999:\n",
    "\t\t\tlast_loss = running_loss / 1000 # loss per batch\n",
    "\t\t\tprint('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "\t\t\ttb_x = epoch_index * len(training_loader) + i + 1\n",
    "\t\t\ttb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "\t\t\trunning_loss = 0.\n",
    "\n",
    "\treturn last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n",
      "finished conv layers\n",
      "avgpooled conv output\n",
      "flattened conv output 1\n",
      "finished linear layers\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Make sure gradient tracking is on, and do a pass over the data\u001b[39;00m\n\u001b[32m     16\u001b[39m cnn.train(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m avg_loss = \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m running_vloss = \u001b[32m0.0\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Set the model to evaluation mode, disabling dropout and using population\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# statistics for batch normalization.\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mtrain_one_epoch\u001b[39m\u001b[34m(epoch_index, tb_writer)\u001b[39m\n\u001b[32m     21\u001b[39m loss = criterion(torch.stack(outputs), labels)\n\u001b[32m     22\u001b[39m running_loss += loss\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Adjust learning weights\u001b[39;00m\n\u001b[32m     26\u001b[39m optimiser.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research/lib/python3.12/site-packages/torch/_tensor.py:525\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    516\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    517\u001b[39m         Tensor.backward,\n\u001b[32m    518\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    523\u001b[39m         inputs=inputs,\n\u001b[32m    524\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    526\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research/lib/python3.12/site-packages/torch/autograd/__init__.py:267\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    262\u001b[39m     retain_graph = create_graph\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    266\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/research/lib/python3.12/site-packages/torch/autograd/graph.py:744\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    742\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    743\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m744\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    745\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    747\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    748\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/cnn_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\tprint('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "\t# Make sure gradient tracking is on, and do a pass over the data\n",
    "\tcnn.train(True)\n",
    "\tavg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "\n",
    "\trunning_vloss = 0.0\n",
    "\t# Set the model to evaluation mode, disabling dropout and using population\n",
    "\t# statistics for batch normalization.\n",
    "\tcnn.eval()\n",
    "\n",
    "\t# Disable gradient computation and reduce memory consumption.\n",
    "\twith torch.no_grad():\n",
    "\t\tfor i, vdata in enumerate(validation_loader):\n",
    "\t\t\tvinputs, vlabels = vdata\n",
    "\t\t\tvoutputs = []\n",
    "\t\t\tfor j in range(batch_size):\n",
    "\t\t\t\tvoutputs.append(cnn(vinputs[j]))\n",
    "\t\t\tvloss = criterion(torch.stack(voutputs), vlabels)\n",
    "\t\t\trunning_vloss += vloss\n",
    "\n",
    "\tavg_vloss = running_vloss / (i + 1)\n",
    "\tprint('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "\t# Log the running loss averaged per batch\n",
    "\t# for both training and validation\n",
    "\twriter.add_scalars('Training vs. Validation Loss',\n",
    "\t\t\t\t\t{ 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "\t\t\t\t\tepoch_number + 1)\n",
    "\twriter.flush()\n",
    "\n",
    "\t# Track best performance, and save the model's state\n",
    "\tif avg_vloss < best_vloss:\n",
    "\t\tbest_vloss = avg_vloss\n",
    "\t\tmodel_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "\t\ttorch.save(cnn.state_dict(), model_path)\n",
    "\n",
    "\tepoch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
